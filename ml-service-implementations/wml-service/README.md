# Open Prediction Service for Watson Machine Learning

This server was generated by the [swagger-codegen](https://github.com/swagger-api/swagger-codegen) project. By using the
[OpenAPI-Spec](https://github.com/swagger-api/swagger-core/wiki) from a remote server, you can easily generate a server stub.

This example uses the [Connexion](https://github.com/zalando/connexion) library on top of Flask.

1. [Getting Started](#getting-started)

2. [Open Prediction Service](#open-prediction-service)

## Getting Started

### Prerequisites

Python 3.7

Docker

### Run the microservice on a Docker container

To build the microservice image

```sh
docker build -t wml-service .
```

To run the microservice, you will need to provide the following parameters:
- WML_API_KEY : your Watson Machine Learning service apikey
- WML_URL : your Watson Machine Learning service url
- WML_INSTANCE_ID : your Watson Machine Learning service instance id


```sh
docker run \
    -p 8080:8080 \
    -e WML_API_KEY=<WML_API_KEY> \
    -e WML_URL=<WML_URL> \
    -e WML_INSTANCE_ID=<WML_INSTANCE_ID> \
    --name wml-service \
    wml-service
```
If you want to run the microservice on another port
```sh
docker run \
    -p <PORT>:8080 \
    -e WML_API_KEY=<WML_API_KEY> \
    -e WML_URL=<WML_URL> \
    -e WML_INSTANCE_ID=<WML_INSTANCE_ID> \
    --name wml-service \
    wml-service
```

To check that you have a running container
```sh
docker ps -f name=wml-service
```

> Your predictive service is available at [http://localhost:8080/](http://localhost:8080/).

> Swagger UI documentation is available at [http://localhost:8080/ui](http://localhost:8080/ui)

Or on the port of choice respectively at `http://localhost:<PORT>/` and `http://localhost:<PORT>/ui`

### Stop the microservice
To stop the container
```sh
docker stop wml-service
```

### Run the microservice without Docker
```sh
pip3 install -r requirements.txt
python3 setup.py install
python3 -m swagger_server
```

### Tests

__To launch unit tests, use tox:__
```
pip3 install tox
tox
```

__To launch tests on your WML instance:__

First, make sure you have a working and configured environment with the following global variables:
- WML_API_KEY : your Watson Machine Learning service apikey
- WML_URL : your Watson Machine Learning service url
- WML_INSTANCE_ID : your Watson Machine Learning service instance id


Then, run tests using tox:
```
pip3 install tox
tox swagger_server/test
```